{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaneEVDSNqiDpPu+vIL6+l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiger1984/Deep-Learing/blob/main/LinearClassifierSGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fi275y7uVgO",
        "outputId": "bd74d304-f7e5-49d6-fc2c-f2034e995abf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss in Iteration 0 0.678971\n",
            "Loss in Iteration 1 0.322714\n",
            "Loss in Iteration 2 0.267420\n",
            "Loss in Iteration 3 0.255062\n",
            "Loss in Iteration 4 0.249043\n",
            "Loss in Iteration 5 0.244157\n",
            "Loss in Iteration 6 0.239648\n",
            "Loss in Iteration 7 0.235394\n",
            "Loss in Iteration 8 0.231365\n",
            "Loss in Iteration 9 0.227544\n",
            "Loss in Iteration 10 0.223915\n",
            "Loss in Iteration 11 0.220466\n",
            "Loss in Iteration 12 0.217185\n",
            "Loss in Iteration 13 0.214062\n",
            "Loss in Iteration 14 0.211086\n",
            "Loss in Iteration 15 0.208247\n",
            "Loss in Iteration 16 0.205537\n",
            "Loss in Iteration 17 0.202948\n",
            "Loss in Iteration 18 0.200473\n",
            "Loss in Iteration 19 0.198105\n",
            "Loss in Iteration 20 0.195837\n",
            "Loss in Iteration 21 0.193663\n",
            "Loss in Iteration 22 0.191578\n",
            "Loss in Iteration 23 0.189577\n",
            "Loss in Iteration 24 0.187655\n",
            "Loss in Iteration 25 0.185808\n",
            "Loss in Iteration 26 0.184032\n",
            "Loss in Iteration 27 0.182322\n",
            "Loss in Iteration 28 0.180675\n",
            "Loss in Iteration 29 0.179089\n",
            "Loss in Iteration 30 0.177559\n",
            "Loss in Iteration 31 0.176083\n",
            "Loss in Iteration 32 0.174658\n",
            "Loss in Iteration 33 0.173282\n",
            "Loss in Iteration 34 0.171953\n",
            "Loss in Iteration 35 0.170667\n",
            "Loss in Iteration 36 0.169424\n",
            "Loss in Iteration 37 0.168220\n",
            "Loss in Iteration 38 0.167055\n",
            "Loss in Iteration 39 0.165926\n",
            "Loss in Iteration 40 0.164833\n",
            "Loss in Iteration 41 0.163772\n",
            "Loss in Iteration 42 0.162744\n",
            "Loss in Iteration 43 0.161746\n",
            "Loss in Iteration 44 0.160778\n",
            "Loss in Iteration 45 0.159838\n",
            "Loss in Iteration 46 0.158925\n",
            "Loss in Iteration 47 0.158037\n",
            "Loss in Iteration 48 0.157175\n",
            "Loss in Iteration 49 0.156336\n",
            "Loss in Iteration 50 0.155521\n",
            "Loss in Iteration 51 0.154728\n",
            "Loss in Iteration 52 0.153956\n",
            "Loss in Iteration 53 0.153204\n",
            "Loss in Iteration 54 0.152473\n",
            "Loss in Iteration 55 0.151760\n",
            "Loss in Iteration 56 0.151067\n",
            "Loss in Iteration 57 0.150390\n",
            "Loss in Iteration 58 0.149731\n",
            "Loss in Iteration 59 0.149089\n",
            "Loss in Iteration 60 0.148463\n",
            "Loss in Iteration 61 0.147852\n",
            "Loss in Iteration 62 0.147256\n",
            "Loss in Iteration 63 0.146675\n",
            "Loss in Iteration 64 0.146108\n",
            "Loss in Iteration 65 0.145554\n",
            "Loss in Iteration 66 0.145014\n",
            "Loss in Iteration 67 0.144486\n",
            "Loss in Iteration 68 0.143971\n",
            "Loss in Iteration 69 0.143468\n",
            "Loss in Iteration 70 0.142977\n",
            "Loss in Iteration 71 0.142497\n",
            "Loss in Iteration 72 0.142028\n",
            "Loss in Iteration 73 0.141569\n",
            "Loss in Iteration 74 0.141121\n",
            "Loss in Iteration 75 0.140683\n",
            "Loss in Iteration 76 0.140255\n",
            "Loss in Iteration 77 0.139836\n",
            "Loss in Iteration 78 0.139427\n",
            "Loss in Iteration 79 0.139027\n",
            "Loss in Iteration 80 0.138635\n",
            "Loss in Iteration 81 0.138252\n",
            "Loss in Iteration 82 0.137877\n",
            "Loss in Iteration 83 0.137510\n",
            "Loss in Iteration 84 0.137151\n",
            "Loss in Iteration 85 0.136800\n",
            "Loss in Iteration 86 0.136456\n",
            "Loss in Iteration 87 0.136119\n",
            "Loss in Iteration 88 0.135790\n",
            "Loss in Iteration 89 0.135467\n",
            "Loss in Iteration 90 0.135151\n",
            "Loss in Iteration 91 0.134842\n",
            "Loss in Iteration 92 0.134539\n",
            "Loss in Iteration 93 0.134242\n",
            "Loss in Iteration 94 0.133951\n",
            "Loss in Iteration 95 0.133666\n",
            "Loss in Iteration 96 0.133387\n",
            "Loss in Iteration 97 0.133114\n",
            "Loss in Iteration 98 0.132846\n",
            "Loss in Iteration 99 0.132583\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# Linear classifier with 4 input features and  3 output values\n",
        "#Doing regression\n",
        "model = nn.Linear(4, 3)\n",
        "\n",
        "# Loss function\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "# Use Stochastic Gradient Descent (SGD)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
        "\n",
        "# 100 training samples with 4 input features each\n",
        "training_input = torch.Tensor([\n",
        "    [0.8, 0.4, 0.4, 0.2],\n",
        "    [0.1, 0.9, 0.2, 0.7],\n",
        "    [0.5, 0.3, 0.8, 0.9],\n",
        "    [0.2, 0.6, 0.1, 0.3],\n",
        "    [0.7, 0.2, 0.4, 0.5],\n",
        "    [0.6, 0.1, 0.9, 0.3],\n",
        "    [0.3, 0.4, 0.5, 0.6],\n",
        "    [0.9, 0.7, 0.2, 0.4],\n",
        "    [0.4, 0.3, 0.6, 0.1],\n",
        "    [0.2, 0.8, 0.3, 0.7]\n",
        "])\n",
        "\n",
        "# Corresponding 2D labels for each input\n",
        "training_output = torch.Tensor([\n",
        "    [1, 0, 0],\n",
        "    [0, 1, 0],\n",
        "    [1, 1, 1],\n",
        "    [0, 0, 0],\n",
        "    [1, 0, 1],\n",
        "    [0, 1, 0],\n",
        "    [1, 1, 0],\n",
        "    [1, 0, 1],\n",
        "    [0, 1, 1],\n",
        "    [0, 0, 1]\n",
        "])\n",
        "\n",
        "# Do training\n",
        "for ep in range(100):\n",
        "    # Zero gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward-pass\n",
        "    #outputs = X.W-Transpose + b\n",
        "\n",
        "    computed_outputs = model(training_input)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = criterion(computed_outputs, training_output)\n",
        "\n",
        "    # Backwardpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Readjust weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print the Loss\n",
        "    print('Loss in Iteration {} {:.6f}'.format(ep, loss.item()))\n",
        "\n"
      ]
    }
  ]
}